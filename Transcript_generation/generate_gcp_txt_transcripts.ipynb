{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ffc08-6574-4957-89f4-6d86ca79581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id=\"\" #GCP Project ID used to call the Speech-to-Text API (API must be enabled)\n",
    "audio_files_directory=\"\" #GCS URI to audio files in format gs://bucket_name/path, files must be stored in subdirectories named after language code of the video\n",
    "gcs_transcripts_directory=\"\" #GCS URI to store generated transcripts in format gs://bucket_name/path\n",
    "model=\"chirp\" #GCP model to use for transcription (i.e. chirp, long)\n",
    "chirp_region=\"us-central1\" #Region to use for Chirp (i.e. europe-west4, us-central1 or asia-southeast1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953022f8-d610-4bb8-9461-d086f9de4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "!(pip install google-cloud-speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e433a-af05-4e0f-9b0c-dbd9cbaa12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import re\n",
    "from typing import List\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud.speech_v2.types import cloud_speech\n",
    "from google.cloud import speech_v2\n",
    "\n",
    "async def transcribe_batch_multiple_files_v2(\n",
    "    project_id: str,\n",
    "    file_array: [],\n",
    "    gcs_output_path: str,\n",
    "    model: str,\n",
    "):\n",
    "    if model==\"chirp\":\n",
    "        client = speech_v2.SpeechAsyncClient(\n",
    "            client_options=ClientOptions(\n",
    "                api_endpoint=f\"{chirp_region}-speech.googleapis.com\",\n",
    "            )\n",
    "        )\n",
    "        location=chirp_region\n",
    "    if model==\"long\":\n",
    "        client = speech_v2.SpeechAsyncClient()\n",
    "        location=\"global\"\n",
    "\n",
    "    default_config = cloud_speech.RecognitionConfig(\n",
    "        auto_decoding_config=cloud_speech.AutoDetectDecodingConfig(),\n",
    "        language_codes=[\"en-US\"],\n",
    "        model=model,\n",
    "        features=cloud_speech.RecognitionFeatures(\n",
    "            enable_automatic_punctuation=True,\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    files=[]\n",
    "    \n",
    "    for file in file_array:\n",
    "        config = cloud_speech.RecognitionConfig(\n",
    "            language_codes=[file[\"language_code\"]],\n",
    "        )\n",
    "        files.append(\n",
    "            cloud_speech.BatchRecognizeFileMetadata(\n",
    "                uri=file[\"gcs_uri\"],\n",
    "                config=config,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    request = speech_v2.BatchRecognizeRequest(\n",
    "        recognizer=f\"projects/{project_id}/locations/{location}/recognizers/_\",\n",
    "        config=default_config,\n",
    "        files=files,\n",
    "        recognition_output_config=cloud_speech.RecognitionOutputConfig(\n",
    "            gcs_output_config=cloud_speech.GcsOutputConfig(\n",
    "                uri=gcs_output_path+\"/\"+model+\"/json\",\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    operation = client.batch_recognize(request=request,timeout=530)\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "    response = await (await operation).result(timeout=530)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c29ef4-f97f-40af-8468-8ea5c7402702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "language_directories=!(gsutil ls {audio_files_directory})\n",
    "file_array=[]\n",
    "\n",
    "for language_directory in language_directories:\n",
    "    \n",
    "    language_code=re.search(\"/([^/]+)/$\",language_directory).group(1)\n",
    "    files=!(gsutil ls {language_directory})\n",
    "    for uri in files:\n",
    "        \n",
    "        file_array.append({\"gcs_uri\": uri,\"language_code\": language_code})\n",
    "\n",
    "print(file_array)\n",
    "number_of_files=len(file_array)\n",
    "print(f\"Number of files: {number_of_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04916570-4d07-489e-abac-c6520c6a478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "\n",
    "def split_array_into_chunks(array, chunk_size):\n",
    "    \"\"\"\n",
    "    Splits an array into chunks of the specified size.\n",
    "\n",
    "    Args:\n",
    "        array: The array to split.\n",
    "        chunk_size: The size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "        A list of chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0, len(array), chunk_size):\n",
    "        chunks.append(array[i : i + chunk_size])\n",
    "        \n",
    "    return chunks\n",
    "\n",
    "arrays=split_array_into_chunks(file_array, 5)\n",
    "start_time = time.time()\n",
    "await asyncio.gather(*[transcribe_batch_multiple_files_v2(project_id, array, gcs_transcripts_directory, model) for array in arrays])\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"Took {duration} to execute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0116e-88c6-44b7-9459-dc419a250f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from google.cloud import storage\n",
    "\n",
    "transcript_array=!(gsutil ls {gcs_transcripts_directory}/{model}/json)\n",
    "\n",
    "for transcript in transcript_array:\n",
    "    print(f\"Fetching results from {transcript}...\")\n",
    "    output_bucket, output_object = re.match(\n",
    "        r\"gs://([^/]+)/(.*)\", transcript\n",
    "    ).group(1, 2)\n",
    "\n",
    "    # Instantiates a Cloud Storage client\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Fetch results from Cloud Storage\n",
    "    bucket = storage_client.bucket(output_bucket)\n",
    "    blob_json = bucket.blob(output_object)\n",
    "    data = json.loads(blob_json.download_as_string(client=None))\n",
    "    raw_transcript=\"\"\n",
    "    \n",
    "    if \"results\" in data:\n",
    "        for alternative in data[\"results\"]:\n",
    "            if \"alternatives\" in alternative:\n",
    "                raw_transcript+=alternative[\"alternatives\"][0][\"transcript\"]\n",
    "\n",
    "    print(f\"Transcript for {transcript}: {raw_transcript}\")\n",
    "    \n",
    "    transcript_id=re.search(f\"{gcs_transcripts_directory}/{model}/json/(.*)_transcript.*\",transcript).group(1)\n",
    "    transcript_path=re.search(\"gs://[^/]+/(.*)\",gcs_transcripts_directory).group(1)\n",
    "   \n",
    "    blob_txt = bucket.blob(transcript_path+\"/\"+model+\"/txt/\"+transcript_id+\".txt\")\n",
    "    blob_txt.upload_from_string(raw_transcript)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
